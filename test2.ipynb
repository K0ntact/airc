{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-23T09:11:17.158208Z",
     "start_time": "2024-12-23T09:11:17.149173Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from typing import Generator, Tuple, List\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def pad_frame_buffer(frame_buffer: List[np.ndarray], buffer_size: int) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Pad frame buffer with last frame if needed.\n",
    "\n",
    "    Args:\n",
    "        frame_buffer: List of frames\n",
    "        buffer_size: Desired buffer size\n",
    "\n",
    "    Returns:\n",
    "        Padded frame buffer\n",
    "    \"\"\"\n",
    "    while len(frame_buffer) < buffer_size:\n",
    "        frame_buffer.append(frame_buffer[-1])\n",
    "    return frame_buffer\n",
    "\n",
    "def extract_frame_tensors(\n",
    "    video_path: str,\n",
    "    frames_per_second: int = 8,\n",
    "    buffer_size: int = 16,\n",
    "    frame_stride: int = 8\n",
    ") -> Generator[Tuple[np.ndarray], None, None]:\n",
    "    \"\"\"\n",
    "    Extract frame tensors from video in a memory-efficient way using frame buffers.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to video file\n",
    "        frames_per_second: Number of frames to extract per second\n",
    "        buffer_size: Number of frames in each tensor buffer\n",
    "        frame_stride: Number of frames to stride between buffers\n",
    "\n",
    "    Returns:\n",
    "        Generator yielding tuples of (frame_tensor, timestamp)\n",
    "        frame_tensor shape: (buffer_size, height, width, channels)\n",
    "    \"\"\"\n",
    "    if not Path(video_path).exists():\n",
    "        raise FileNotFoundError(f\"Video file not found: {video_path}\")\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(\"Failed to open video file\")\n",
    "\n",
    "    try:\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        duration = total_frames / fps\n",
    "        target_frames = np.linspace(0,\n",
    "                                    total_frames - 1,\n",
    "                                    num=int(duration * frames_per_second),\n",
    "                                    dtype=np.int32)\n",
    "\n",
    "        frame_buffer = []\n",
    "        current_frame = 0\n",
    "\n",
    "        for target_idx in target_frames:\n",
    "            # Skip to target frame\n",
    "            while current_frame < target_idx:\n",
    "                cap.read()\n",
    "                current_frame += 1\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame_buffer.append(frame)\n",
    "            current_frame += 1\n",
    "\n",
    "            if len(frame_buffer) == buffer_size:\n",
    "                print(current_frame)\n",
    "                frame_tensor = np.stack(frame_buffer, axis=0)\n",
    "                yield frame_tensor\n",
    "\n",
    "                # Slide buffer window by stride\n",
    "                frame_buffer = frame_buffer[frame_stride:]\n",
    "\n",
    "        # Handle remaining frames if any\n",
    "        if len(frame_buffer) >= buffer_size // 2:\n",
    "            frame_buffer = pad_frame_buffer(frame_buffer, buffer_size)\n",
    "            frame_tensor = np.stack(frame_buffer, axis=0)\n",
    "            yield frame_tensor\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "\n",
    "def process_video(video_path: str) -> None:\n",
    "    \"\"\"Example usage of the frame tensor extractor\"\"\"\n",
    "    frame_tensors = extract_frame_tensors(\n",
    "        video_path,\n",
    "        frames_per_second=8,\n",
    "        buffer_size=16,\n",
    "        frame_stride=8\n",
    "    )\n",
    "\n",
    "    for idx, tensor in enumerate(frame_tensors):\n",
    "        print(f\"Frame tensor {idx}: shape {tensor.shape}\")"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T09:11:17.199737Z",
     "start_time": "2024-12-23T09:11:17.169808Z"
    }
   },
   "cell_type": "code",
   "source": "process_video(\"./datasets/ATMA-V/videos/train/BT-aug/3-aug-h_flip.mp4\")",
   "id": "20963399e479061e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "Frame tensor 0: shape (16, 224, 224, 3)\n",
      "87\n",
      "Frame tensor 1: shape (16, 224, 224, 3)\n",
      "118\n",
      "Frame tensor 2: shape (16, 224, 224, 3)\n",
      "148\n",
      "Frame tensor 3: shape (16, 224, 224, 3)\n",
      "178\n",
      "Frame tensor 4: shape (16, 224, 224, 3)\n",
      "208\n",
      "Frame tensor 5: shape (16, 224, 224, 3)\n",
      "238\n",
      "Frame tensor 6: shape (16, 224, 224, 3)\n",
      "268\n",
      "Frame tensor 7: shape (16, 224, 224, 3)\n",
      "299\n",
      "Frame tensor 8: shape (16, 224, 224, 3)\n",
      "329\n",
      "Frame tensor 9: shape (16, 224, 224, 3)\n",
      "359\n",
      "Frame tensor 10: shape (16, 224, 224, 3)\n",
      "389\n",
      "Frame tensor 11: shape (16, 224, 224, 3)\n",
      "419\n",
      "Frame tensor 12: shape (16, 224, 224, 3)\n",
      "450\n",
      "Frame tensor 13: shape (16, 224, 224, 3)\n",
      "480\n",
      "Frame tensor 14: shape (16, 224, 224, 3)\n",
      "510\n",
      "Frame tensor 15: shape (16, 224, 224, 3)\n",
      "540\n",
      "Frame tensor 16: shape (16, 224, 224, 3)\n",
      "570\n",
      "Frame tensor 17: shape (16, 224, 224, 3)\n",
      "601\n",
      "Frame tensor 18: shape (16, 224, 224, 3)\n",
      "631\n",
      "Frame tensor 19: shape (16, 224, 224, 3)\n",
      "661\n",
      "Frame tensor 20: shape (16, 224, 224, 3)\n",
      "691\n",
      "Frame tensor 21: shape (16, 224, 224, 3)\n",
      "721\n",
      "Frame tensor 22: shape (16, 224, 224, 3)\n",
      "Frame tensor 23: shape (16, 224, 224, 3)\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
